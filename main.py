# -*- coding: utf-8 -*-
"""Part1.ipynb

Automatically generated by Colaboratory.


"""

import sys
import requests
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn.metrics import r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
from matplotlib.pyplot import figure

energy_eff = pd.read_excel('https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx')
energy_eff

correlation_matrix = energy_eff.corr().round(2)
sns.heatmap(data=correlation_matrix, annot=True)

X = dataset.iloc[:, :-1]
y = dataset[['critical_temp']]

s = StandardScaler()
X = pd.DataFrame(s.fit(X).fit_transform(X))

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

X_train = pd.DataFrame(data=X_train)
X_train['HeatingLoad'] = list(Y_train)

X_test = pd.DataFrame(data=X_test)
X_test['HeatingLoad'] = list(Y_test)


def StochasticGD(X, y):
    weight = np.random.randn(1, 6)
    bias = np.random.randn(1, 1)

    epoch = 1
    loss_arr = []
    learning_rate = 0.001

    while (epoch < 75):
        feature_set = X.iloc[:, 0:6].values
        result_set = X.iloc[:, -1].values
        weight_update = weight
        bias_update = bias
        loss = 0
        predicted_set = []

        for i in range(len(result_set)):
            weight_update = (-2 * feature_set[i]) * (result_set[i] - np.dot(feature_set[i], weight.T) - bias)
            bias_update = (-2) * (result_set[i] - np.dot(feature_set[i], weight.T) - bias)

            weight = weight - learning_rate * weight_update
            bias = bias - learning_rate * bias_update

            predicted_val = np.dot(feature_set[i], weight.T)
            predicted_set.append(predicted_val)

        loss = mean_squared_error(predicted_set, result_set)
        print(" Loss: %f             Epoch:  %i" % (loss, epoch))
        loss_arr.append(loss)

        learning_rate = learning_rate / 1.005
        epoch = epoch + 1

    plt.figure(figsize=(25, 6))
    plt.title("Loss graph: ")
    plt.xlabel("EPOCH")
    plt.ylabel("MSE")
    plt.plot(loss_arr, label='Loss')

    return weight, bias


weight, bias = StochasticGD(X_train, Y_train)  # Training the model

print('Ideal weights and bias found as-\n')
print('Weights = ', weight, '\n')
print('bias = ', bias)


def predict_on(x, weight, bias):
    predictions = []
    for i in range(len(x)):
        feature_set = x
        X_test = feature_set.iloc[:, 0:6].values
        y = np.asscalar(np.dot(weight, X_test[i]) + bias)
        predictions.append(y)
    return np.array(predictions)


print("TRAINING DATA RESULTS\n")

y_train_predict = predict_on(X_train, weight, bias)
rmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))
r2 = r2_score(Y_train, y_train_predict)
print('Training data- \nRoot mean squared error is {}'.format(rmse))
print('R2 score is', r2, '\n')

count = 0
indexes = []
for i in range(len(Y_train)):
    indexes.append(count)
    count = count + 1

Y_train.index = indexes

plt.figure(figsize=(35, 9))
plt.plot(Y_train, label='Actual')
plt.plot(y_train_predict, label='Predicted')
plt.legend(prop={'size': 16})
plt.show()

print("\n\nTRAINING DATA RESULTS\n")

y_test_predict = predict_on(X_test, weight, bias)
rmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))
r2 = r2_score(Y_test, y_test_predict)
print('Testing data- \nRoot mean squared error is {}'.format(rmse))
print('R2 score is ', r2, '\n')

count = 0
indexes = []
for i in range(len(Y_test)):
    indexes.append(count)
    count = count + 1

Y_test.index = indexes

plt.figure(figsize=(35, 9))
plt.plot(Y_test, label='Actual', )
plt.plot(y_test_predict, label='Predicted')
plt.show()